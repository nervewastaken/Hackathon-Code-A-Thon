{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nerve/Coding/Hackathon/voice/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import torch\n",
    "import torchaudio\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import requests\n",
    "import json\n",
    "import spacy\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newupload.wav\n",
      "Loaded file from newupload.wav\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Step 1: Simulate someone uploading a file to the Flask server\n",
    "# Note: This step should be performed by the client, not in the notebook\n",
    "\n",
    "# Step 2: Wait for the file to be uploaded and retrieve it from the server\n",
    "\n",
    "file_name = 'newupload.wav'  # Replace with the actual file name\n",
    "file_path = os.path.join(file_name)\n",
    "print(file_path)\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    # Load the file in the Jupyter Notebook\n",
    "    audio = AudioSegment.from_wav(file_path)\n",
    "    print(f\"Loaded file from {file_path}\")\n",
    "else:\n",
    "    print(f\"File {file_name} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nerve/Coding/Hackathon/voice/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription:  THE STALE SMELL OF OLD BEER LINGERS IT TAKES HEAT TO BRING OUT THE ODOR A COLD DIP RESTORES HEALTH AND ZEST A SALT PICKLE TASTES FINE WITH HAM TAKOZAL PASTORE ARE MY FAVORITE A ZESTFUL FOOD IS THE HOT CROSS BUN\n"
     ]
    }
   ],
   "source": [
    "# Load the model and processor\n",
    "model_name = \"facebook/wav2vec2-base-960h\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_name)\n",
    "\n",
    "# Load your uploaded audio file using pydub\n",
    "\n",
    "audio = AudioSegment.from_wav(file_path)\n",
    "\n",
    "# Convert pydub audio to numpy array\n",
    "speech_array = np.array(audio.get_array_of_samples(), dtype=np.float32)\n",
    "sampling_rate = audio.frame_rate\n",
    "\n",
    "# Normalize the audio array\n",
    "speech_array = speech_array / np.iinfo(np.int16).max\n",
    "\n",
    "# Ensure the audio is mono\n",
    "if audio.channels > 1:\n",
    "    speech_array = speech_array.reshape((-1, audio.channels)).mean(axis=1)\n",
    "\n",
    "# Resample to 16000 Hz if necessary\n",
    "if sampling_rate != 16000:\n",
    "    from scipy.signal import resample\n",
    "    speech_array = resample(speech_array, int(16000 * len(speech_array) / sampling_rate))\n",
    "    sampling_rate = 16000\n",
    "\n",
    "# Process the audio file\n",
    "input_values = processor(speech_array, sampling_rate=sampling_rate, return_tensors=\"pt\").input_values\n",
    "\n",
    "# Perform the transcription\n",
    "with torch.no_grad():\n",
    "    logits = model(input_values).logits\n",
    "\n",
    "# Decode the predicted ids to text\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.decode(predicted_ids[0])\n",
    "\n",
    "print(\"Transcription: \", transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response: The right tire is not okay. \n",
      "\n",
      "\n",
      "Let me know if you have any other phrases you'd like me to check! ðŸ˜Š  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example API request (use your own request method and URL as necessary)\n",
    "url = \"http://localhost:11434/api/generate\"\n",
    "data = {\n",
    "    \"model\": \"gemma2:latest\",\n",
    "    \"prompt\": transcription + \" - correct this if there are spelling errors return only the corrected text\",\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data)\n",
    "\n",
    "# Parse the JSON response\n",
    "response_json = response.json()\n",
    "\n",
    "# Extract the relevant response content (ignore the metadata)\n",
    "model_response = response_json.get(\"response\", \"No response found\")\n",
    "\n",
    "# Print the cleaned response\n",
    "print(\"Model Response:\", model_response)\n",
    "\n",
    "model_response = transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis Result: The statement might be negative despite containing 'okay' words.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Load the small English model in spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "transcription = \"This is not okay\"\n",
    "\n",
    "# Define the \"okay\" words lexicon\n",
    "okay_words = set([\n",
    "    \"okay\", \"all right\", \"working\", \"good\", \"fine\", \"no issues\",\n",
    "    \"everything is okay\", \"all clear\", \"no problem\", \"in order\",\n",
    "    \"smooth\", \"operational\", \"functioning\", \"on track\", \"intact\", \n",
    "    \"secure\", \"stable\", \"sound\"\n",
    "])\n",
    "\n",
    "# Define a simple negation lexicon\n",
    "negation_words = set([\"not\", \"no\", \"never\", \"none\", \"nobody\", \"nothing\"])\n",
    "\n",
    "# Process the transcription with spaCy\n",
    "doc = nlp(transcription.lower())\n",
    "\n",
    "# Tokenize the transcription and check for negation and okay words\n",
    "tokens = [token.text for token in doc]\n",
    "contains_okay_word = any(word in okay_words for word in tokens)\n",
    "contains_negation = any(word in negation_words for word in tokens)\n",
    "\n",
    "\n",
    "# Analyze the response based on lexicons\n",
    "if contains_negation and contains_okay_word:\n",
    "    analysis_result = \"The statement might be negative despite containing 'okay' words.\"\n",
    "    label = 1\n",
    "elif contains_okay_word:\n",
    "    analysis_result = \"The statement is positive.\"\n",
    "    label = 0\n",
    "else:\n",
    "    analysis_result = \"The statement is negative or unclear.\"\n",
    "    label = 1\n",
    "\n",
    "# Print the analysis result\n",
    "print(\"Analysis Result:\", analysis_result)\n",
    "print(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the HF_TOKEN and SECRET_KEY\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "secret_key = os.getenv(\"SECRET_KEY\")\n",
    "\n",
    "# Use hf_token for authentication if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL CONNECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time: (datetime.datetime(2024, 8, 10, 6, 54, 18, 732791, tzinfo=datetime.timezone.utc),)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "# Database connection credentials\n",
    "connection_params = {\n",
    "    \"user\": \"postgres.keqffvaytvbaqniavqtg\",\n",
    "    \"host\": \"aws-0-us-east-1.pooler.supabase.com\",\n",
    "    \"database\": \"postgres\",\n",
    "    \"password\": \"9ChJhmA5BIkZUvr1\",\n",
    "    \"port\": 6543,  # Default port for Supabase Postgres\n",
    "    \"sslmode\": \"require\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Establish a connection to the PostgreSQL database\n",
    "    connection = psycopg2.connect(**connection_params)\n",
    "\n",
    "    # Create a cursor object to interact with the database\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Example query\n",
    "    cursor.execute(\"SELECT NOW();\")\n",
    "\n",
    "    # Fetch and print the result of the query\n",
    "    result = cursor.fetchone()\n",
    "    print(\"Current Time:\", result)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error connecting to the database:\", e)\n",
    "\n",
    "finally:\n",
    "    # Always close the cursor and connection to free up resources\n",
    "    if cursor:\n",
    "        cursor.close()\n",
    "    if connection:\n",
    "        connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "duration = 8  # seconds\n",
    "sample_rate = 44100  # Sample rate\n",
    "\n",
    "print(\"Recording...\")\n",
    "# Record audio in mono\n",
    "audio_data = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='int16')\n",
    "sd.wait()  # Wait until the recording is finished\n",
    "print(\"Recording finished!\")\n",
    "\n",
    "# Save the recording as a WAV file\n",
    "wav_file = \"output.wav\"\n",
    "write(wav_file, sample_rate, audio_data)\n",
    "\n",
    "print(f\"Audio saved as {wav_file}\")\n",
    "\n",
    "# If you want to store the WAV data as a variable\n",
    "audio_variable = audio_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "voice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
